{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt\n",
    "# ! pip install -r requirements.txt # Uncomment this line to install dependencies in a new environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /Users/isaiah/.cache/kagglehub/datasets/joebeachcapital/technology-mergers-and-acquisitions/versions/1\n"
     ]
    }
   ],
   "source": [
    "# !pip install kagglehub\n",
    "\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# # Download selected version\n",
    "# path = kagglehub.dataset_download(\"shivamb/company-acquisitions-7-top-companies/versions/1\")\n",
    "\n",
    "# print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"joebeachcapital/technology-mergers-and-acquisitions\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Acquisitions ID     Acquired Company  \\\n",
      "0                      [24]7 acquired Tellme in 2012               Tellme   \n",
      "1                         3Com acquired Palm in 1997                 Palm   \n",
      "2  Adobe Systems acquired Accelio Corporation in ...  Accelio Corporation   \n",
      "3  Adobe Systems acquired Accelio Corporation in ...  Accelio Corporation   \n",
      "4  Adobe Systems acquired Accelio Corporation in ...  Accelio Corporation   \n",
      "\n",
      "  Acquiring Company  Year of acquisition announcement Deal announced on  \\\n",
      "0             [24]7                              2012         1/02/2012   \n",
      "1              3Com                              1997         1/06/1997   \n",
      "2             Adobe                              2002        15/04/2002   \n",
      "3             Adobe                              2002        15/04/2002   \n",
      "4             Adobe                              2002        15/04/2002   \n",
      "\n",
      "                Price       Status        Terms  \\\n",
      "0  Undisclosed amount  Undisclosed  Undisclosed   \n",
      "1  Undisclosed amount  Undisclosed  Undisclosed   \n",
      "2  Undisclosed amount  Undisclosed  Undisclosed   \n",
      "3  Undisclosed amount  Undisclosed  Undisclosed   \n",
      "4  Undisclosed amount  Undisclosed  Undisclosed   \n",
      "\n",
      "                                 Acquisition Profile  \\\n",
      "0  http://www.crunchbase.com/acquisition/a9e7a5ac...   \n",
      "1  http://www.crunchbase.com/acquisition/65869a9a...   \n",
      "2  http://www.crunchbase.com/acquisition/ba5294ea...   \n",
      "3  http://www.crunchbase.com/acquisition/ba5294ea...   \n",
      "4  http://www.crunchbase.com/acquisition/ba5294ea...   \n",
      "\n",
      "                                                News  ...  \\\n",
      "0  Microsoft and 24/7 Inc. Join Forces to Deliver...  ...   \n",
      "1        Investors bless 3Com-USR merger - CNET News  ...   \n",
      "2         Adobe Systems acquired Accelio Corporation  ...   \n",
      "3         Adobe Systems acquired Accelio Corporation  ...   \n",
      "4         Adobe Systems acquired Accelio Corporation  ...   \n",
      "\n",
      "                                Description_Acquired Homepage_Acquired  \\\n",
      "0                                                NaN               NaN   \n",
      "1                                                NaN               NaN   \n",
      "2  Accelio Corporation Formerly known as Jetform ...               NaN   \n",
      "3  Accelio Corporation Formerly known as Jetform ...               NaN   \n",
      "4  Accelio Corporation Formerly known as Jetform ...               NaN   \n",
      "\n",
      "  Twitter_Acquired Acquired by  \\\n",
      "0              NaN         NaN   \n",
      "1              NaN         NaN   \n",
      "2              NaN       Adobe   \n",
      "3              NaN       Adobe   \n",
      "4              NaN       Adobe   \n",
      "\n",
      "                                        API_Acquired             Name  \\\n",
      "0                                                NaN              NaN   \n",
      "1                                                NaN              NaN   \n",
      "2  http://api.crunchbase.com/v/2/organization/acc...        Amy Banse   \n",
      "3  http://api.crunchbase.com/v/2/organization/acc...  Charles Geschke   \n",
      "4  http://api.crunchbase.com/v/2/organization/acc...   Dan Rosensweig   \n",
      "\n",
      "                               CrunchBase Profile_y                Role  \\\n",
      "0                                               NaN                 NaN   \n",
      "1                                               NaN                 NaN   \n",
      "2        http://www.crunchbase.com/person/amy-banse  Board of Directors   \n",
      "3  http://www.crunchbase.com/person/charles-geschke             Founder   \n",
      "4   http://www.crunchbase.com/person/dan-rosensweig  Board of Directors   \n",
      "\n",
      "  Companies                                            Image_y  \n",
      "0       NaN                                                NaN  \n",
      "1       NaN                                                NaN  \n",
      "2     Adobe  http://a3.images.crunchbase.com/image/upload/c...  \n",
      "3     Adobe  http://a1.images.crunchbase.com/image/upload/c...  \n",
      "4     Adobe  http://a3.images.crunchbase.com/image/upload/c...  \n",
      "\n",
      "[5 rows x 54 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load all CSVs\n",
    "acquiring_companies = pd.read_csv(\"data/Acquiring Tech Companies.csv\")\n",
    "acquired_companies = pd.read_csv(\"data/Acquired Tech Companies.csv\")\n",
    "acquisitions = pd.read_csv(\"data/Acquisitions.csv\")\n",
    "founders_board = pd.read_csv(\"data/Founders and Board Members.csv\")\n",
    "\n",
    "# Link acquisitions table with acquiring companies\n",
    "merged_1 = acquisitions.merge(\n",
    "    acquiring_companies,\n",
    "    how=\"left\",\n",
    "    left_on=\"Acquiring Company\",\n",
    "    right_on=\"CrunchBase Profile\",\n",
    "    suffixes=(\"\", \"_Acquirer\")\n",
    ")\n",
    "\n",
    "# Link with acquired companies\n",
    "merged_2 = merged_1.merge(\n",
    "    acquired_companies,\n",
    "    how=\"left\",\n",
    "    on=\"Acquisitions ID\",\n",
    "    suffixes=(\"\", \"_Acquired\")\n",
    ")\n",
    "\n",
    "# You can also join founders/board members with acquiring companies\n",
    "merged_full = merged_2.merge(\n",
    "    founders_board,\n",
    "    how=\"left\",\n",
    "    left_on=\"Acquiring Company\",\n",
    "    right_on=\"Companies\"\n",
    ")\n",
    "\n",
    "# Now merged_full contains all the linked info\n",
    "print(merged_full.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 1 (Censored Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price</th>\n",
       "      <th>Year Founded_Acquired</th>\n",
       "      <th>Market Categories_Acquired</th>\n",
       "      <th>Number of Employees</th>\n",
       "      <th>Total Funding ($)</th>\n",
       "      <th>IPO</th>\n",
       "      <th>Country (HQ)_Acquired</th>\n",
       "      <th>State / Region (HQ)_Acquired</th>\n",
       "      <th>Acquiring Company</th>\n",
       "      <th>Number of Acquisitions</th>\n",
       "      <th>Country (HQ)</th>\n",
       "      <th>Year of acquisition announcement</th>\n",
       "      <th>Deal announced on</th>\n",
       "      <th>Status</th>\n",
       "      <th>Terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Undisclosed amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[24]7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>1/02/2012</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Undisclosed amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1/06/1997</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Undisclosed amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>15/04/2002</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Undisclosed amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>15/04/2002</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Undisclosed amount</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>15/04/2002</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Price  Year Founded_Acquired Market Categories_Acquired  \\\n",
       "0  Undisclosed amount                    NaN                        NaN   \n",
       "1  Undisclosed amount                    NaN                        NaN   \n",
       "2  Undisclosed amount                    NaN                        NaN   \n",
       "3  Undisclosed amount                    NaN                        NaN   \n",
       "4  Undisclosed amount                    NaN                        NaN   \n",
       "\n",
       "  Number of Employees  Total Funding ($)  IPO Country (HQ)_Acquired  \\\n",
       "0                 NaN                NaN  NaN                   NaN   \n",
       "1                 NaN                NaN  NaN                   NaN   \n",
       "2                 NaN                NaN  NaN                Canada   \n",
       "3                 NaN                NaN  NaN                Canada   \n",
       "4                 NaN                NaN  NaN                Canada   \n",
       "\n",
       "  State / Region (HQ)_Acquired Acquiring Company  Number of Acquisitions  \\\n",
       "0                          NaN             [24]7                     NaN   \n",
       "1                          NaN              3Com                     NaN   \n",
       "2                      Ontario             Adobe                     NaN   \n",
       "3                      Ontario             Adobe                     NaN   \n",
       "4                      Ontario             Adobe                     NaN   \n",
       "\n",
       "  Country (HQ)  Year of acquisition announcement Deal announced on  \\\n",
       "0          NaN                              2012         1/02/2012   \n",
       "1          NaN                              1997         1/06/1997   \n",
       "2          NaN                              2002        15/04/2002   \n",
       "3          NaN                              2002        15/04/2002   \n",
       "4          NaN                              2002        15/04/2002   \n",
       "\n",
       "        Status        Terms  \n",
       "0  Undisclosed  Undisclosed  \n",
       "1  Undisclosed  Undisclosed  \n",
       "2  Undisclosed  Undisclosed  \n",
       "3  Undisclosed  Undisclosed  \n",
       "4  Undisclosed  Undisclosed  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# keep only relevant columns\n",
    "phase1_cols = [\n",
    "    # dependent variable\n",
    "    'Price',\n",
    "    \n",
    "    # target firm features\n",
    "    'Year Founded_Acquired',\n",
    "    'Market Categories_Acquired',\n",
    "    'Number of Employees',\n",
    "    'Total Funding ($)',\n",
    "    'IPO',\n",
    "    'Country (HQ)_Acquired',\n",
    "    'State / Region (HQ)_Acquired',\n",
    "    \n",
    "    # acquirer features\n",
    "    'Acquiring Company',\n",
    "    'Number of Acquisitions',\n",
    "    'Country (HQ)',\n",
    "    \n",
    "    # contextual / timing\n",
    "    'Year of acquisition announcement',\n",
    "    'Deal announced on',\n",
    "    'Status',\n",
    "    'Terms'\n",
    "]\n",
    "\n",
    "merged_phase1 = merged_full[phase1_cols].copy()\n",
    "\n",
    "# preview the cleaned frame\n",
    "merged_phase1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns for simplicity\n",
    "merged_phase1.rename(columns={\n",
    "    'Price': 'deal_value',\n",
    "    'Year Founded_Acquired': 'year_founded_target',\n",
    "    'Market Categories_Acquired': 'sector_target',\n",
    "    'Number of Employees': 'employees_target',\n",
    "    'Total Funding ($)': 'funding_target',\n",
    "    'IPO': 'ipo_status',\n",
    "    'Country (HQ)_Acquired': 'country_target',\n",
    "    'Country (HQ)': 'country_acquirer',\n",
    "    'Number of Acquisitions': 'acquirer_experience'\n",
    "}, inplace=True)\n",
    "\n",
    "# drop duplicates and rows with no key info\n",
    "merged_phase1.drop_duplicates(inplace=True)\n",
    "merged_phase1.dropna(subset=['deal_value', 'year_founded_target', 'sector_target'], how='all', inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove currency symbols, commas, and text like 'USD' or 'M'\n",
    "merged_phase1['deal_value'] = (\n",
    "    merged_phase1['deal_value']\n",
    "    .astype(str)\n",
    "    .str.replace(r'[^0-9.\\-]', '', regex=True)  # keep only digits and dots\n",
    ")\n",
    "\n",
    "# convert to float; invalid entries become NaN\n",
    "merged_phase1['deal_value'] = pd.to_numeric(merged_phase1['deal_value'], errors='coerce')\n",
    "\n",
    "# now re-run the censoring logic\n",
    "merged_phase1['is_censored'] = merged_phase1['deal_value'].isna() | \\\n",
    "                               merged_phase1['deal_value'].astype(str).str.contains('undisclosed', case=False, na=False)\n",
    "\n",
    "# compute threshold safely, ignoring NaN\n",
    "D = merged_phase1['deal_value'].dropna().quantile(0.75)\n",
    "merged_phase1['lower_bound'] = D\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding for Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns used: ['sector_target', 'country_target', 'country_acquirer', 'Status', 'Terms']\n",
      "Numeric columns used: ['year_founded_target', 'employees_target', 'funding_target', 'acquirer_experience']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaiah/aetos/lib/python3.12/site-packages/sklearn/utils/extmath.py:1101: RuntimeWarning: invalid value encountered in divide\n",
      "  updated_mean = (last_sum + new_sum) / updated_sample_count\n",
      "/Users/isaiah/aetos/lib/python3.12/site-packages/sklearn/utils/extmath.py:1106: RuntimeWarning: invalid value encountered in divide\n",
      "  T = new_sum / new_sample_count\n",
      "/Users/isaiah/aetos/lib/python3.12/site-packages/sklearn/utils/extmath.py:1126: RuntimeWarning: invalid value encountered in divide\n",
      "  new_unnormalized_variance -= correction**2 / new_sample_count\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# --- define categorical and numeric columns ---\n",
    "cat_cols = ['sector_target', 'country_target', 'country_acquirer', 'Status', 'Terms']\n",
    "num_cols = ['year_founded_target', 'employees_target', 'funding_target', 'acquirer_experience']\n",
    "\n",
    "# --- verify columns exist before encoding ---\n",
    "existing_cat_cols = [c for c in cat_cols if c in merged_phase1.columns]\n",
    "existing_num_cols = [c for c in num_cols if c in merged_phase1.columns]\n",
    "\n",
    "print(\"Categorical columns used:\", existing_cat_cols)\n",
    "print(\"Numeric columns used:\", existing_num_cols)\n",
    "\n",
    "# --- one-hot encode categorical ---\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoded_cats = pd.DataFrame(\n",
    "    encoder.fit_transform(merged_phase1[existing_cat_cols]),\n",
    "    columns=encoder.get_feature_names_out(existing_cat_cols),\n",
    "    index=merged_phase1.index\n",
    ")\n",
    "\n",
    "# --- scale numeric ---\n",
    "scaler = StandardScaler()\n",
    "scaled_nums = pd.DataFrame(\n",
    "    scaler.fit_transform(merged_phase1[existing_num_cols]),\n",
    "    columns=existing_num_cols,\n",
    "    index=merged_phase1.index\n",
    ")\n",
    "\n",
    "# --- combine encoded + scaled features ---\n",
    "X = pd.concat([encoded_cats, scaled_nums], axis=1)\n",
    "\n",
    "# --- define target and censoring indicator ---\n",
    "y = merged_phase1['deal_value']\n",
    "is_censored = merged_phase1['is_censored']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>deal_value</th>\n",
       "      <th>year_founded_target</th>\n",
       "      <th>sector_target</th>\n",
       "      <th>employees_target</th>\n",
       "      <th>funding_target</th>\n",
       "      <th>ipo_status</th>\n",
       "      <th>country_target</th>\n",
       "      <th>State / Region (HQ)_Acquired</th>\n",
       "      <th>Acquiring Company</th>\n",
       "      <th>acquirer_experience</th>\n",
       "      <th>country_acquirer</th>\n",
       "      <th>Year of acquisition announcement</th>\n",
       "      <th>Deal announced on</th>\n",
       "      <th>Status</th>\n",
       "      <th>Terms</th>\n",
       "      <th>is_censored</th>\n",
       "      <th>lower_bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[24]7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2012</td>\n",
       "      <td>1/02/2012</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3Com</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1997</td>\n",
       "      <td>1/06/1997</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Canada</td>\n",
       "      <td>Ontario</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2002</td>\n",
       "      <td>15/04/2002</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1994</td>\n",
       "      <td>31/08/1994</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Adobe</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2006</td>\n",
       "      <td>28/06/1905</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20108</th>\n",
       "      <td>20000000.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>Curated Web, Photo Sharing, Search, Email, Soc...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2009</td>\n",
       "      <td>23/07/2009</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20123</th>\n",
       "      <td>29600000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1998</td>\n",
       "      <td>1/12/1998</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20138</th>\n",
       "      <td>350000000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2007</td>\n",
       "      <td>1/09/2007</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Cash</td>\n",
       "      <td>False</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20153</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>Hospitality, Restaurants, Travel, Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>United States</td>\n",
       "      <td>California</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2014</td>\n",
       "      <td>12/08/2014</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20168</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Enterprise Software</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>China</td>\n",
       "      <td>Beijing</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2013</td>\n",
       "      <td>18/07/2013</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>Undisclosed</td>\n",
       "      <td>True</td>\n",
       "      <td>625000000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        deal_value  year_founded_target  \\\n",
       "0              NaN                  NaN   \n",
       "1              NaN                  NaN   \n",
       "2              NaN                  NaN   \n",
       "15             NaN               1984.0   \n",
       "28             NaN                  NaN   \n",
       "...            ...                  ...   \n",
       "20108   20000000.0               2004.0   \n",
       "20123   29600000.0                  NaN   \n",
       "20138  350000000.0                  NaN   \n",
       "20153          NaN               2012.0   \n",
       "20168          NaN                  NaN   \n",
       "\n",
       "                                           sector_target employees_target  \\\n",
       "0                                                    NaN              NaN   \n",
       "1                                                    NaN              NaN   \n",
       "2                                                    NaN              NaN   \n",
       "15                                              Software              NaN   \n",
       "28                                              Software              NaN   \n",
       "...                                                  ...              ...   \n",
       "20108  Curated Web, Photo Sharing, Search, Email, Soc...              NaN   \n",
       "20123                                                NaN              NaN   \n",
       "20138                                                NaN              NaN   \n",
       "20153           Hospitality, Restaurants, Travel, Mobile              NaN   \n",
       "20168                                Enterprise Software              NaN   \n",
       "\n",
       "       funding_target ipo_status country_target State / Region (HQ)_Acquired  \\\n",
       "0                 NaN        NaN            NaN                          NaN   \n",
       "1                 NaN        NaN            NaN                          NaN   \n",
       "2                 NaN        NaN         Canada                      Ontario   \n",
       "15                NaN        NaN  United States                   Washington   \n",
       "28                NaN        NaN  United States                   California   \n",
       "...               ...        ...            ...                          ...   \n",
       "20108             NaN        NaN  United States                   California   \n",
       "20123             NaN        NaN            NaN                          NaN   \n",
       "20138             NaN        NaN            NaN                          NaN   \n",
       "20153             NaN        NaN  United States                   California   \n",
       "20168             NaN        NaN          China                      Beijing   \n",
       "\n",
       "      Acquiring Company  acquirer_experience country_acquirer  \\\n",
       "0                 [24]7                  NaN              NaN   \n",
       "1                  3Com                  NaN              NaN   \n",
       "2                 Adobe                  NaN              NaN   \n",
       "15                Adobe                  NaN              NaN   \n",
       "28                Adobe                  NaN              NaN   \n",
       "...                 ...                  ...              ...   \n",
       "20108             Yahoo                  NaN              NaN   \n",
       "20123             Yahoo                  NaN              NaN   \n",
       "20138             Yahoo                  NaN              NaN   \n",
       "20153             Yahoo                  NaN              NaN   \n",
       "20168             Yahoo                  NaN              NaN   \n",
       "\n",
       "       Year of acquisition announcement Deal announced on       Status  \\\n",
       "0                                  2012         1/02/2012  Undisclosed   \n",
       "1                                  1997         1/06/1997  Undisclosed   \n",
       "2                                  2002        15/04/2002  Undisclosed   \n",
       "15                                 1994        31/08/1994  Undisclosed   \n",
       "28                                 2006        28/06/1905  Undisclosed   \n",
       "...                                 ...               ...          ...   \n",
       "20108                              2009        23/07/2009  Undisclosed   \n",
       "20123                              1998         1/12/1998  Undisclosed   \n",
       "20138                              2007         1/09/2007  Undisclosed   \n",
       "20153                              2014        12/08/2014  Undisclosed   \n",
       "20168                              2013        18/07/2013  Undisclosed   \n",
       "\n",
       "             Terms  is_censored  lower_bound  \n",
       "0      Undisclosed         True  625000000.0  \n",
       "1      Undisclosed         True  625000000.0  \n",
       "2      Undisclosed         True  625000000.0  \n",
       "15     Undisclosed         True  625000000.0  \n",
       "28     Undisclosed         True  625000000.0  \n",
       "...            ...          ...          ...  \n",
       "20108         Cash        False  625000000.0  \n",
       "20123         Cash        False  625000000.0  \n",
       "20138         Cash        False  625000000.0  \n",
       "20153  Undisclosed         True  625000000.0  \n",
       "20168  Undisclosed         True  625000000.0  \n",
       "\n",
       "[1639 rows x 17 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(merged_phase1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solver for Censored Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(CVXPY) Oct 06 04:18:31 PM: Your problem has 201 variables, 1218 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 06 04:18:31 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 06 04:18:31 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 06 04:18:31 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Using cached ASA map, for faster compilation (bypassing reduction chain).\n",
      "(CVXPY) Oct 06 04:18:31 PM: Finished problem compilation (took 2.829e-03 seconds).\n",
      "(CVXPY) Oct 06 04:18:31 PM: Invoking solver OSQP  to obtain a solution.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Problem status: optimal\n",
      "(CVXPY) Oct 06 04:18:31 PM: Optimal value: 8.724e+03\n",
      "(CVXPY) Oct 06 04:18:31 PM: Compilation took 2.829e-03 seconds\n",
      "(CVXPY) Oct 06 04:18:31 PM: Solver (including time spent in interface) took 2.149e-03 seconds\n",
      "(CVXPY) Oct 06 04:18:31 PM: Your problem has 201 variables, 1218 constraints, and 0 parameters.\n",
      "(CVXPY) Oct 06 04:18:31 PM: It is compliant with the following grammars: DCP, DQCP\n",
      "(CVXPY) Oct 06 04:18:31 PM: (If you need to solve this problem multiple times, but with different data, consider using parameters.)\n",
      "(CVXPY) Oct 06 04:18:31 PM: CVXPY will first compile your problem; then, it will invoke a numerical solver to obtain a solution.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Your problem is compiled with the CPP canonicalization backend.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Compiling problem (target solver=OSQP).\n",
      "(CVXPY) Oct 06 04:18:31 PM: Reduction chain: CvxAttr2Constr -> Qp2SymbolicQp -> QpMatrixStuffing -> OSQP\n",
      "(CVXPY) Oct 06 04:18:31 PM: Applying reduction CvxAttr2Constr\n",
      "(CVXPY) Oct 06 04:18:31 PM: Applying reduction Qp2SymbolicQp\n",
      "(CVXPY) Oct 06 04:18:31 PM: Applying reduction QpMatrixStuffing\n",
      "(CVXPY) Oct 06 04:18:31 PM: Applying reduction OSQP\n",
      "(CVXPY) Oct 06 04:18:31 PM: Finished problem compilation (took 7.351e-03 seconds).\n",
      "(CVXPY) Oct 06 04:18:31 PM: Invoking solver OSQP  to obtain a solution.\n",
      "(CVXPY) Oct 06 04:18:31 PM: Problem status: optimal\n",
      "(CVXPY) Oct 06 04:18:31 PM: Optimal value: 7.226e+03\n",
      "(CVXPY) Oct 06 04:18:31 PM: Compilation took 7.351e-03 seconds\n",
      "(CVXPY) Oct 06 04:18:31 PM: Solver (including time spent in interface) took 1.167e-02 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 201 / 488 feature columns (dropped low-variance).\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   8.7241e+03   1.48e-04   3.77e-04  -5.43e-02   3.77e-04   5.20e-01    7.30e-05s\n",
      "  25   8.7242e+03   3.63e-05   1.64e-04  -1.16e-02   1.64e-04   5.20e-01    6.51e-04s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   unsuccessful\n",
      "number of iterations: 25\n",
      "optimal objective:    8724.1543\n",
      "dual objective:       8724.1658\n",
      "duality gap:          -1.1585e-02\n",
      "primal-dual integral: 1.0071e+04\n",
      "run time:             1.19e-03s\n",
      "optimal rho estimate: 3.46e-01\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "===============================================================================\n",
      "                                     CVXPY                                     \n",
      "                                     v1.7.3                                    \n",
      "===============================================================================\n",
      "-------------------------------------------------------------------------------\n",
      "                                  Compilation                                  \n",
      "-------------------------------------------------------------------------------\n",
      "-------------------------------------------------------------------------------\n",
      "                                Numerical solver                               \n",
      "-------------------------------------------------------------------------------\n",
      "-----------------------------------------------------------------\n",
      "           OSQP v1.0.0  -  Operator Splitting QP Solver\n",
      "              (c) The OSQP Developer Team\n",
      "-----------------------------------------------------------------\n",
      "problem:  variables n = 622, constraints m = 1639\n",
      "          nnz(P) + nnz(A) = 8259\n",
      "settings: algebra = Built-in,\n",
      "          OSQPInt = 4 bytes, OSQPFloat = 8 bytes,\n",
      "          linear system solver = QDLDL v0.1.8,\n",
      "          eps_abs = 1.0e-03, eps_rel = 1.0e-03,\n",
      "          eps_prim_inf = 1.0e-04, eps_dual_inf = 1.0e-04,\n",
      "          rho = 1.00e-01 (adaptive: 50 iterations),\n",
      "          sigma = 1.00e-06, alpha = 1.60, max_iter = 20000\n",
      "          check_termination: on (interval 25, duality gap: on),\n",
      "          time_limit: 1.00e+10 sec,\n",
      "          scaling: on (10 iterations), scaled_termination: off\n",
      "          warm starting: on, polishing: on, \n",
      "iter   objective    prim res   dual res   gap        rel kkt    rho         time\n",
      "   1   0.0000e+00   5.00e+00   5.79e+02  -3.04e+03   5.79e+02   1.00e-01    8.10e-04s\n",
      " 150   6.5537e+03   1.36e+00   7.86e-02  -5.55e+02   1.36e+00   5.35e-01*   3.90e-03s\n",
      " 200   7.1203e+03   2.23e-01   6.38e-01  -9.77e+01   6.38e-01   5.35e-01    4.98e-03s\n",
      " 400   7.2250e+03   4.55e-03   1.91e-02  -1.39e+00   1.91e-02   5.35e-01    8.89e-03s\n",
      " 450   7.2259e+03   1.90e-03   8.24e-03  -5.90e-01   8.24e-03   5.35e-01    9.84e-03s\n",
      "\n",
      "status:               solved\n",
      "solution polishing:   unsuccessful\n",
      "number of iterations: 450\n",
      "optimal objective:    7225.8849\n",
      "dual objective:       7226.4744\n",
      "duality gap:          -5.8955e-01\n",
      "primal-dual integral: 9.7798e+03\n",
      "run time:             1.02e-02s\n",
      "optimal rho estimate: 3.06e-01\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "                                    Summary                                    \n",
      "-------------------------------------------------------------------------------\n",
      "Solver status: optimal\n",
      "Objective value: 7225.884919313646\n",
      "count    1639.000000\n",
      "mean     1004.597883\n",
      "std         1.294155\n",
      "min      1000.172439\n",
      "25%      1005.000056\n",
      "50%      1005.000812\n",
      "75%      1005.001359\n",
      "max      1005.004118\n",
      "Name: predicted_price, dtype: float64\n",
      "Censored constraints violated on 99 rows (should be 0).\n"
     ]
    }
   ],
   "source": [
    "# !pip install cvxpy\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "\n",
    "# --- Sanitize arrays ---\n",
    "# Convert to numpy just in case\n",
    "X_unc = np.asarray(X_uncensored, dtype=float)\n",
    "X_cen = np.asarray(X_censored, dtype=float)\n",
    "y_unc = np.asarray(y_uncensored, dtype=float)\n",
    "\n",
    "# Replace NaN/Inf and cap extreme magnitudes\n",
    "def clean(A, cap=1e3):\n",
    "    A = np.nan_to_num(A, nan=0.0, posinf=cap, neginf=-cap)\n",
    "    A[np.abs(A) > cap] = np.sign(A[np.abs(A) > cap]) * cap\n",
    "    return A\n",
    "\n",
    "X_unc = clean(X_unc, cap=1e2)\n",
    "X_cen = clean(X_cen, cap=1e2)\n",
    "y_unc = clean(y_unc, cap=1e3)\n",
    "\n",
    "# drop zero-variance columns so we can condition better\n",
    "col_var = X_unc.var(axis=0)\n",
    "keep = col_var > 1e-12\n",
    "X_unc = X_unc[:, keep]\n",
    "X_cen = X_cen[:, keep]\n",
    "print(f\"Kept {keep.sum()} / {keep.size} feature columns (dropped low-variance).\")\n",
    "\n",
    "# standardise y and threshold\n",
    "y_mean, y_std = y_unc.mean(), (y_unc.std() if y_unc.std() > 1e-12 else 1.0)\n",
    "y_sc = (y_unc - y_mean) / y_std\n",
    "D_scaled = float(np.clip((D_val - y_mean) / y_std, -5.0, 5.0))\n",
    "\n",
    "# define convex opti problem\n",
    "n = X_unc.shape[1]\n",
    "c = cp.Variable(n)\n",
    "\n",
    "ridge = 1e-1  # regularisation strength\n",
    "objective = cp.Minimize(cp.sum_squares(X_unc @ c - y_sc) + ridge * cp.sum_squares(c))\n",
    "\n",
    "ridge = 1e0  # increase ridge term\n",
    "result = prob.solve(\n",
    "    solver=cp.OSQP,\n",
    "    eps_abs=1e-4, eps_rel=1e-4,\n",
    "    max_iter=30000,\n",
    "    polish=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "\n",
    "constraints = []\n",
    "if X_cen.shape[0] > 0:\n",
    "    constraints = [X_cen @ c >= D_scaled]\n",
    "\n",
    "prob = cp.Problem(objective, constraints)\n",
    "\n",
    "# try OSQP first, fallback to SCS-indirect\n",
    "try:\n",
    "    res = prob.solve(\n",
    "        solver=cp.OSQP,\n",
    "        verbose=True,\n",
    "        eps_abs=1e-3,\n",
    "        eps_rel=1e-3,\n",
    "        max_iter=20000,\n",
    "        polish=True\n",
    "    )\n",
    "except (cp.SolverError, Exception):\n",
    "    res = prob.solve(\n",
    "        solver=cp.SCS,\n",
    "        verbose=True,\n",
    "        use_indirect=True,\n",
    "        eps=1e-3,\n",
    "        max_iters=5000,\n",
    "        scale=0.1,\n",
    "        acceleration_lookback=10\n",
    "    )\n",
    "\n",
    "print(\"Solver status:\", prob.status)\n",
    "print(\"Objective value:\", res)\n",
    "\n",
    "# rebuild full design and compute predictions\n",
    "if prob.status in (\"optimal\", \"optimal_inaccurate\"):\n",
    "    X_full = np.asarray(X, dtype=float)[:, keep]\n",
    "    X_full = clean(X_full, cap=1e2)\n",
    "    c_opt = c.value\n",
    "    y_pred_sc = X_full @ c_opt\n",
    "    y_pred = y_pred_sc * y_std + y_mean\n",
    "    merged_phase1[\"predicted_price\"] = y_pred\n",
    "    print(merged_phase1[\"predicted_price\"].describe())\n",
    "else:\n",
    "    print(\"⚠️ Solver did not converge. Status:\", prob.status)\n",
    "\n",
    "# check if constraints met\n",
    "if X_cen.shape[0] > 0 and prob.status in (\"optimal\", \"optimal_inaccurate\"):\n",
    "    viol = (X_cen @ c.value) < D_scaled - 1e-6\n",
    "    print(\"Censored constraints violated on\", int(viol.sum()), \"rows (should be 0).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 2 - Covariance Estimation\n",
    "### From Phase 1 we have:\n",
    "- merged_phase1['predicted_price']  (proxy for monthly profit/value)\n",
    "- 'Deal announced on' (date), and a company identifier\n",
    "- Choose which entity drives the portfolio: 'Acquiring Company' or 'Acquired Company'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities (n): 27\n",
      "Panel shape (T x n): (207, 27)\n",
      "mu shape: (27,) | Sigma_emp shape: (27, 27)\n",
      "Sparse precision estimated. Status: optimal_inaccurate\n",
      "\n",
      "\n",
      "Optimal inaccurate explains the resiudals hit the preset tolerance\n",
      "There is still a valid S (precision matrix) are invertible, PSD and usable for Phase 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/isaiah/aetos/lib/python3.12/site-packages/cvxpy/problems/problem.py:1539: UserWarning: Solution may be inaccurate. Try another solver, adjusting the solver settings, or solve with verbose=True for more information.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "df = merged_phase1.copy()\n",
    "\n",
    "# parse time and choose the entity dimension\n",
    "df['deal_date'] = pd.to_datetime(df['Deal announced on'], errors='coerce')\n",
    "df = df.dropna(subset=['deal_date'])\n",
    "\n",
    "# monthly bucket\n",
    "df['month'] = df['deal_date'].dt.to_period('M').dt.to_timestamp()\n",
    "\n",
    "# choose which side to model in portfolios\n",
    "entity_col = 'Acquiring Company'   # or 'Acquired Company'\n",
    "\n",
    "# build a monthly panel: sum across deals per (month, entity)\n",
    "panel = (\n",
    "    df.groupby(['month', entity_col], dropna=True)['predicted_price']\n",
    "      .sum()                               # monthly total value/profit proxy\n",
    "      .unstack(entity_col)                 # index=month, columns=entity\n",
    "      .sort_index()\n",
    ")\n",
    "\n",
    "# keep entities with enough history\n",
    "min_months = 6\n",
    "panel = panel.loc[:, panel.notna().sum() >= min_months]\n",
    "\n",
    "# fill months with no deals as zeros (interpreting “no M&A cashflow” as 0)\n",
    "panel = panel.fillna(0.0)\n",
    "\n",
    "# standardize per-column to control scale before cov\n",
    "# for raw “profit” covariance, we can skip standardization, here i decided to demeans\n",
    "# get deviation from monthly average profit hence subtract tryna get what the covariance measures\n",
    "panel_centered = panel - panel.mean(axis=0)\n",
    "\n",
    "# dompute sample mean and covariance (Markowitz inputs)\n",
    "# μ: per-entity average monthly value; Σ: covariance across entities\n",
    "mu = panel.mean(axis=0).to_numpy()             # shape (n_entities,)\n",
    "Sigma_emp = np.cov(panel_centered.to_numpy(), rowvar=False, bias=False)  # (n x n)\n",
    "entities = panel.columns.tolist()\n",
    "\n",
    "print(\"Entities (n):\", len(entities))\n",
    "print(\"Panel shape (T x n):\", panel.shape)\n",
    "print(\"mu shape:\", mu.shape, \"| Sigma_emp shape:\", Sigma_emp.shape)\n",
    "\n",
    "# ==========================================================\n",
    "# empirical covariances can be noisy or nearly-singular\n",
    "# we can use precision matrix estimation to stabilize\n",
    "# Sparse inverse covariance (Graphical-Lasso style)\n",
    "# Solve:    min_{S ≻ 0}  -logdet(S) + tr(S * Σ_emp) + λ * ||S||_1_offdiag\n",
    "# Returns a precision matrix S; can invert to get a stabilized covariance.\n",
    "# ==========================================================\n",
    "\n",
    "use_sparse_precision = True\n",
    "lambda_glasso = 1e-2  # tune (start with 1e-2 to 1e-1; larger = sparser)\n",
    "\n",
    "Sigma_glasso = None\n",
    "S_val = None\n",
    "\n",
    "if use_sparse_precision:\n",
    "    n = Sigma_emp.shape[0]\n",
    "    S = cp.Variable((n, n), symmetric=True)\n",
    "\n",
    "    # Off-diagonal L1 penalty (don’t penalize the diagonal)\n",
    "    offdiag = cp.norm1(S - cp.multiply(np.eye(n), S))\n",
    "\n",
    "    # Objective: convex log-det program\n",
    "    obj = cp.Minimize(-cp.log_det(S) + cp.trace(S @ Sigma_emp) + lambda_glasso * offdiag)\n",
    "\n",
    "    # Constraint: S ≻ 0 (enforced via S >> 0 with a small PSD floor for numerics)\n",
    "    constraints = [S >> 1e-6 * np.eye(n)]\n",
    "    prob = cp.Problem(obj, constraints)\n",
    "    _ = prob.solve(solver=cp.SCS, verbose=False, use_indirect=True, eps=1e-4, max_iters=5000)\n",
    "\n",
    "    if prob.status in (\"optimal\", \"optimal_inaccurate\"):\n",
    "        S_val = S.value\n",
    "        # Invert S to get a stabilized covariance estimate\n",
    "        # Add a tiny ridge for safety before inversion\n",
    "        Sigma_glasso = np.linalg.pinv(S_val + 1e-8 * np.eye(n))\n",
    "        print(\"Sparse precision estimated. Status:\", prob.status)\n",
    "        print(\"\\n\")\n",
    "    else:\n",
    "        print(\"Glasso solve status:\", prob.status, \"— using empirical Sigma only.\\n\")\n",
    "\n",
    "print(\"Optimal inaccurate explains the resiudals hit the preset tolerance\")\n",
    "print(\"There is still a valid S (precision matrix) are invertible, PSD and usable for Phase 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phase 3 - Portfolio Optimisation\n",
    "### Inputs expected from Phase 2:\n",
    "   - mu            : (n,) vector of expected monthly profits/returns\n",
    "   - Sigma_emp     : (n,n) empirical covariance\n",
    "   - Sigma_glasso  : (n,n) optional stabilised covariance (or None)\n",
    "   - entities      : list of length n with asset/firm names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontier points: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gamma</th>\n",
       "      <th>expected_return</th>\n",
       "      <th>risk_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>388.208534</td>\n",
       "      <td>23.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001616</td>\n",
       "      <td>388.208534</td>\n",
       "      <td>23.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002610</td>\n",
       "      <td>388.208534</td>\n",
       "      <td>23.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.004217</td>\n",
       "      <td>388.208534</td>\n",
       "      <td>23.999501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006813</td>\n",
       "      <td>388.208534</td>\n",
       "      <td>23.999501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      gamma  expected_return   risk_std\n",
       "0  0.001000       388.208534  23.999501\n",
       "1  0.001616       388.208534  23.999501\n",
       "2  0.002610       388.208534  23.999501\n",
       "3  0.004217       388.208534  23.999501\n",
       "4  0.006813       388.208534  23.999501"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen portfolio (most return-seeking): {'gamma': np.float64(0.001), 'expected_return': 388.2085339980848, 'risk_std': np.float64(23.999500908467187)}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AOL</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IBM</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yahoo</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SAP</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Qualcomm</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       entity  weight\n",
       "0      Google     1.0\n",
       "1         AOL     0.0\n",
       "2         IBM     0.0\n",
       "3       Yahoo     0.0\n",
       "4     Twitter     0.0\n",
       "5    Symantec     0.0\n",
       "6  Salesforce     0.0\n",
       "7         SAP     0.0\n",
       "8    Qualcomm     0.0\n",
       "9      Oracle     0.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sum of weights: 1.0\n",
      "Target-return portfolio solved. Return ≥ 87.36942302837012\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Dropbox</td>\n",
       "      <td>0.218579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>0.072817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dell</td>\n",
       "      <td>0.065050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Qualcomm</td>\n",
       "      <td>0.061116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Salesforce</td>\n",
       "      <td>0.049456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AT&amp;T</td>\n",
       "      <td>0.046294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Intel</td>\n",
       "      <td>0.042048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Oracle</td>\n",
       "      <td>0.036707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Symantec</td>\n",
       "      <td>0.036209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adobe</td>\n",
       "      <td>0.035705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        entity    weight\n",
       "9      Dropbox  0.218579\n",
       "16    LinkedIn  0.072817\n",
       "8         Dell  0.065050\n",
       "20    Qualcomm  0.061116\n",
       "22  Salesforce  0.049456\n",
       "1         AT&T  0.046294\n",
       "15       Intel  0.042048\n",
       "19      Oracle  0.036707\n",
       "23    Symantec  0.036209\n",
       "2        Adobe  0.035705"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# choose covariance & make it numerically safe\n",
    "# make sure the covariance matrix is symmetric positive-semidefinite.\n",
    "# If any eigenvalue is slightly negative (numerical noise), add a small ridge so the QP is strictly convex.\n",
    "Sigma = Sigma_glasso if ('Sigma_glasso' in globals() and Sigma_glasso is not None) else Sigma_emp\n",
    "Sigma = 0.5 * (Sigma + Sigma.T)                    # symmetrise\n",
    "eigvals = np.linalg.eigvalsh(Sigma)\n",
    "min_eig = eigvals.min()\n",
    "if min_eig < 1e-8:\n",
    "    Sigma += (1e-8 - min_eig) * np.eye(Sigma.shape[0])  # PSD floor\n",
    "\n",
    "n = len(mu)\n",
    "mu = np.asarray(mu).reshape(-1)                     # ensure shape (n,)\n",
    "Sigma = np.asarray(Sigma, dtype=float)\n",
    "\n",
    "# mean–variance scalarised QP\n",
    "#   min_w  -mu^T w + gamma * w^T Sigma w\n",
    "#   s.t.   1^T w = 1,  w >= 0\n",
    "\n",
    "# First term (–μᵀw) = maximise expected return.\n",
    "# Second term (γ wᵀΣw) = penalise risk (variance).\n",
    "# γ controls risk-aversion:\n",
    "# • small γ → chase returns,\n",
    "# • large γ → prioritise safety.\n",
    "# Constraints enforce a fully-invested, long-only portfolio.\n",
    "def solve_markowitz_scalarized(mu, Sigma, gamma, solver=\"OSQP\"):\n",
    "    w = cp.Variable(n)\n",
    "    obj = -mu @ w + gamma * cp.quad_form(w, Sigma)\n",
    "    cons = [cp.sum(w) == 1, w >= 0]\n",
    "    prob = cp.Problem(cp.Minimize(obj), cons)\n",
    "    try:\n",
    "        _ = prob.solve(solver=getattr(cp, solver), verbose=False, max_iter=20000, polish=True)\n",
    "    except Exception:\n",
    "        _ = prob.solve(solver=cp.SCS, verbose=False, use_indirect=True, eps=1e-4, max_iters=8000, scale=0.1)\n",
    "    return w.value, prob.status\n",
    "\n",
    "# efficient frontier by sweeping gamma\n",
    "# This sweeps 25 values of γ from 0.001 (return-hungry) to 100 (risk-averse), \n",
    "# building the efficient frontier – the trade-off curve of risk vs return.\n",
    "\n",
    "gammas = np.logspace(-3, 2, 25)   # from return-seeking to risk-averse\n",
    "frontier = []\n",
    "weights_by_gamma = {}\n",
    "\n",
    "for g in gammas:\n",
    "    w_opt, status = solve_markowitz_scalarized(mu, Sigma, gamma=g, solver=\"OSQP\")\n",
    "    if status not in (\"optimal\", \"optimal_inaccurate\") or w_opt is None:\n",
    "        continue\n",
    "    w_opt = np.clip(w_opt, 0, None)  # guard tiny negatives\n",
    "    w_opt = w_opt / w_opt.sum()      # renormalise\n",
    "    ret = float(mu @ w_opt)\n",
    "    risk = float(w_opt @ Sigma @ w_opt)             # portfolio variance\n",
    "    frontier.append((g, ret, np.sqrt(risk)))\n",
    "    weights_by_gamma[g] = w_opt\n",
    "\n",
    "frontier_df = pd.DataFrame(frontier, columns=[\"gamma\", \"expected_return\", \"risk_std\"]) # store each solutions y var, expected return and risk\n",
    "print(\"Frontier points:\", frontier_df.shape[0])\n",
    "print(f\"{frontier_df.shape[0]} feasible portoflios were found.\")\n",
    "display(frontier_df.head())\n",
    "\n",
    "# pick a representative portfolio\n",
    "# Example choices:\n",
    "#   - most return-seeking (smallest gamma)\n",
    "#   - mid gamma\n",
    "#   - most risk-averse (largest gamma)\n",
    "chosen_gamma = frontier_df.loc[frontier_df['gamma'].idxmin(), 'gamma']  # most return-seeking which is the smallest y\n",
    "w_star = weights_by_gamma[chosen_gamma] # most aggressive investor\n",
    "w_star = np.clip(w_star, 0, None); w_star = w_star / w_star.sum()\n",
    "\n",
    "# summary stats for chosen_gamma\n",
    "ret_star = float(mu @ w_star)\n",
    "risk_star = float(w_star @ Sigma @ w_star)          # variance\n",
    "summary = {\n",
    "    \"gamma\": chosen_gamma,\n",
    "    \"expected_return\": ret_star,\n",
    "    \"risk_std\": np.sqrt(risk_star)\n",
    "}\n",
    "print(\"Chosen portfolio (most return-seeking):\", summary)\n",
    "\n",
    "# tidy weights table\n",
    "w_tbl = pd.DataFrame({\n",
    "    \"entity\": entities,\n",
    "    \"weight\": w_star\n",
    "}).sort_values(\"weight\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "display(w_tbl.head(10))\n",
    "print(\"Sum of weights:\", w_tbl['weight'].sum())\n",
    "\n",
    "# target-return min-variance variant\n",
    "#   min_w  w^T Σ w\n",
    "#   s.t.   μ^T w ≥ r_min, 1^T w = 1, w ≥ 0\n",
    "# fix a required minimum return rₘᵢₙ (e.g. median μ) and find the portfolio with minimum risk that still achieves that return\n",
    "\n",
    "def solve_markowitz_target(mu, Sigma, r_min, solver=\"OSQP\"):\n",
    "    w = cp.Variable(n)\n",
    "    obj = cp.quad_form(w, Sigma)\n",
    "    cons = [cp.sum(w) == 1, w >= 0, mu @ w >= r_min]\n",
    "    prob = cp.Problem(cp.Minimize(obj), cons)\n",
    "    try:\n",
    "        _ = prob.solve(solver=getattr(cp, solver), verbose=False, max_iter=20000, polish=True)\n",
    "    except Exception:\n",
    "        _ = prob.solve(solver=cp.SCS, verbose=False, use_indirect=True, eps=1e-4, max_iters=8000, scale=0.1)\n",
    "    return w.value, prob.status\n",
    "\n",
    "# Example: set r_min to the median of μ\n",
    "r_min = float(np.median(mu))\n",
    "w_trg, status_trg = solve_markowitz_target(mu, Sigma, r_min, solver=\"OSQP\")\n",
    "if status_trg in (\"optimal\", \"optimal_inaccurate\") and w_trg is not None:\n",
    "    w_trg = np.clip(w_trg, 0, None); w_trg = w_trg / w_trg.sum()\n",
    "    print(\"Target-return portfolio solved. Return ≥\", r_min)\n",
    "    display(pd.DataFrame({\"entity\": entities, \"weight\": w_trg}).sort_values(\"weight\", ascending=False).head(10))\n",
    "else:\n",
    "    print(\"Target-return problem status:\", status_trg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontier saved to: results/frontier.csv\n",
      "Portfolio weights saved to: results/portfolio_weights.csv\n",
      "Covariance heatmap saved to: results/covariance_heatmap.png\n",
      "All result files exported successfully.\n",
      "Frontier → results/frontier.csv\n",
      "Weights → results/portfolio_weights.csv\n",
      "Heatmap → results/covariance_heatmap.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ensure results directory exists\n",
    "os.makedirs(\"results\", exist_ok=True)\n",
    "\n",
    "# ==========================================================\n",
    "# Export Efficient Frontier (risk vs expected return)\n",
    "# ==========================================================\n",
    "frontier_path = \"results/frontier.csv\"\n",
    "frontier_df.to_csv(frontier_path, index=False)\n",
    "print(f\"Frontier saved to: {frontier_path}\")\n",
    "\n",
    "# ==========================================================\n",
    "# Export Portfolio Weights\n",
    "# ==========================================================\n",
    "weights_path = \"results/portfolio_weights.csv\"\n",
    "w_tbl.to_csv(weights_path, index=False)\n",
    "print(f\"Portfolio weights saved to: {weights_path}\")\n",
    "\n",
    "# ==========================================================\n",
    "# Covariance Heatmap Plot\n",
    "# ==========================================================\n",
    "# Choose covariance matrix (stabilized if available)\n",
    "Sigma_plot = Sigma_glasso if 'Sigma_glasso' in globals() and Sigma_glasso is not None else Sigma_emp\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(Sigma_plot, cmap=\"coolwarm\", aspect=\"auto\")\n",
    "plt.title(\"Covariance Matrix Heatmap (Σ)\", fontsize=14, pad=10)\n",
    "plt.colorbar(label=\"Covariance value\")\n",
    "plt.xticks(ticks=np.arange(len(entities)), labels=entities, rotation=90)\n",
    "plt.yticks(ticks=np.arange(len(entities)), labels=entities)\n",
    "plt.tight_layout()\n",
    "\n",
    "heatmap_path = \"results/covariance_heatmap.png\"\n",
    "plt.savefig(heatmap_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "print(f\"Covariance heatmap saved to: {heatmap_path}\")\n",
    "\n",
    "# ==========================================================\n",
    "# Final confirmation\n",
    "# ==========================================================\n",
    "print(\"All result files exported successfully.\")\n",
    "print(f\"Frontier → {frontier_path}\\nWeights → {weights_path}\\nHeatmap → {heatmap_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimiser placed 100 % weight on Google.  \n",
    "\n",
    "Reason: with \\( \\gamma \\) tiny, the risk penalty \\( \\gamma w^\\top \\Sigma w \\) is negligible,  \n",
    "so it simply picks the asset with the largest \\( \\mu \\) (highest predicted average return).  \n",
    "This is the corner portfolio on the extreme right of the frontier.  \n",
    "\n",
    "Mathematically:  \n",
    "\n",
    "$$\n",
    "w^* = e_i \\quad \\text{for } i = \\arg\\max_i \\mu_i\n",
    "$$\n",
    "\n",
    "For the **target return portfolio**, we have:\n",
    "\n",
    "Here the constraint \n",
    "\n",
    "$$\n",
    "\\mu^\\top w \\ge 87.37\n",
    "$$\n",
    "\n",
    "forces diversification.  \n",
    "The optimiser now minimises variance while satisfying that return floor.  \n",
    "You get a spread across ~10 firms, each < 22 %, achieving the target with the lowest possible risk.  \n",
    "\n",
    "**Economically:**  \n",
    "Instead of betting everything on one high-return firm, the model balances exposure among correlated but complementary companies (cloud, hardware, telecom) to meet the same profit level more safely.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "| **Phase** | **Mathematical goal** | **What the output confirms** |\n",
    "|:--|:--|:--|\n",
    "| **1. Censored Regression** | Recover missing M\\&A deal prices | Convex QP solved; full predicted dataset available |\n",
    "| **2. Covariance Estimation** | Compute $$\\mu$$ and $$\\Sigma$$ of predicted profits | 27 entities $$\\times$$ 207 months → well-conditioned covariance |\n",
    "| **3. Portfolio Optimisation** | Use $$(\\mu, \\Sigma)$$ to build efficient portfolios | Frontier + optimal weights show how expected value vs risk trade-off |\n",
    "\n",
    "**Convex pipeline summary:**\n",
    "\n",
    "$$\n",
    "\\text{Incomplete data} \n",
    "\\;\\xrightarrow[\\text{Phase 1}]{}\\; \n",
    "\\text{Estimated values} \n",
    "\\;\\xrightarrow[\\text{Phase 2}]{}\\; \n",
    "(\\mu, \\Sigma) \n",
    "\\;\\xrightarrow[\\text{Phase 3}]{}\\; \n",
    "\\text{Optimal allocation } w\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (aetos)",
   "language": "python",
   "name": "aetos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
